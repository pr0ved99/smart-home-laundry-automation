import rclpy
from rclpy.node import Node
from rclpy.action import ActionClient
from rclpy.qos import qos_profile_sensor_data
from dobot_msgs.action import PointToPoint
from dobot_msgs.srv import SuctionCupControl
from sensor_msgs.msg import Image, CameraInfo
from std_msgs.msg import String  # [ì¶”ê°€] ë©”ì‹œì§€ íƒ€ì…
from cv_bridge import CvBridge
import cv2
import numpy as np
import time
import threading

# =========================================================
# ğŸ¯ [ì„¤ì •] ì´ˆê¸° ROI ì˜ì—­ (í™”ë©´ í•´ìƒë„ 640x480 ê¸°ì¤€)
# í•„ìš”ì— ë”°ë¼ x, y, w, h ê°’ì„ ìˆ˜ì •í•˜ì„¸ìš”.
# =========================================================
DEFAULT_ROI = (650, 100, 250, 260) # (x, y, w, h)
# =========================================================

# ... (TRANSFORM_MATRIX ë“± ê¸°ì¡´ ì„¤ì • ìœ ì§€) ...
TRANSFORM_MATRIX = np.array([
    [-26.78282, 801.92427, 263.07654],
    [865.05996, -32.57398, -11.01282],
    [-0.18015, -1.41963, 1.00000]
])

OFFSET_X = 0.0
OFFSET_Y = 0.0
OFFSET_Z = 20.0
Z_OFFSET_CONSTANT = 354.72
Z_SAFE = 90.0

DROP_LOCATIONS = {
    'Red':    [120.0, 175.0, 3.0, 0.0],
    'Blue':   [120.0, 175.0, 3.0, 0.0],
    'Green':  [53.0, 175.0, 3.0, 0.0],
    'Yellow': [53.0, 175.0, 3.0, 0.0],
}

class ColorSorter(Node):
    def __init__(self):
        super().__init__('dobot_color_sorter')
        self._action_client = ActionClient(self, PointToPoint, 'PTP_action')
        self._suction_client = self.create_client(SuctionCupControl, '/dobot_suction_cup_service')
        self.bridge = CvBridge()
        
        # Subscribers
        self.create_subscription(CameraInfo, '/camera/camera/color/camera_info', self.info_callback, 10)
        self.create_subscription(Image, '/camera/camera/aligned_depth_to_color/image_raw', self.depth_callback, qos_profile_sensor_data)
        self.create_subscription(Image, '/camera/camera/color/image_raw', self.color_callback, qos_profile_sensor_data)
        
        # [ì¶”ê°€] ì»¨ë² ì´ì–´ ìƒíƒœ ìˆ˜ì‹ 
        self.create_subscription(String, '/conveyor_status', self.conveyor_status_callback, 10)

        self.latest_depth_img = None
        self.camera_intrinsics = None
        self.dist_coeffs = None
        
        # [ìˆ˜ì •] ì´ˆê¸° ROI ì„¤ì •
        self.roi_start = None; self.roi_end = None
        self.selecting = False
        self.roi_selected = True  # ì²˜ìŒë¶€í„° ì„ íƒëœ ìƒíƒœë¡œ ì‹œì‘
        self.roi_rect = DEFAULT_ROI # ê¸°ë³¸ê°’ ì ìš©
        
        self.color_ranges = {
            'Red':    [([0, 100, 100], [10, 255, 255]), ([170, 100, 100], [180, 255, 255])],
            'Blue':   [([100, 150, 0], [140, 255, 255])],
            'Green':  [([40, 70, 70], [80, 255, 255])],
            'Yellow': [([20, 100, 100], [30, 255, 255])]
        }
        self.scan_data = {color: {'buffer': [], 'fixed': None, 'depth_m': 0.0} for color in self.color_ranges}
        self.is_collecting = False
        self.is_robot_busy = False 
        
        self.window_name = "Dobot Smart Sorter"
        cv2.namedWindow(self.window_name)
        cv2.setMouseCallback(self.window_name, self.mouse_callback)
        self.get_logger().info("âœ… Ready! Default ROI applied. Waiting for Conveyor...")

    # [ìˆ˜ì •] ì»¨ë² ì´ì–´ ìƒíƒœ ì½œë°±
    def conveyor_status_callback(self, msg):
        # "stopped" ë©”ì‹œì§€ëŠ” ì´ë¯¸ ë²¨íŠ¸ê°€ 8ì´ˆ ì´ë™ì„ ëë‚¸ ë’¤ì— ë‚ ì•„ì˜µë‹ˆë‹¤.
        if msg.data == "stopped" and not self.is_robot_busy:
            self.get_logger().info("ğŸ“¦ Conveyor Stopped Signal Received.")
            self.get_logger().info("â³ Waiting 1.0s for vibration to settle...")
            
            # í™”ë©´ì´ ë©ˆì¶”ì§€ ì•Šë„ë¡ ì“°ë ˆë“œë¡œ 1ì´ˆ ëŒ€ê¸° í›„ ì¸¡ì • ì‹œì‘
            threading.Thread(target=self.start_measurement).start()

    # [ì¶”ê°€] 1ì´ˆ ì•ˆì •í™” ëŒ€ê¸° í›„ ì¸¡ì • ì‹œì‘ í•¨ìˆ˜
    def start_measurement(self):
        time.sleep(1.0)  # ê´€ì„±ìœ¼ë¡œ í”ë“¤ë¦¬ëŠ” ê²ƒ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)
        
        self.reset_data()
        self.is_collecting = True  # ì´ ë³€ìˆ˜ê°€ Trueê°€ ë˜ì–´ì•¼ ROI ì•ˆì—ì„œ ì¸¡ì •ì„ ì‹œì‘í•¨
        self.get_logger().info("ğŸ“¸ Stabilization Complete. Measurement Started! (Check ROI)")

    # ... (get_smart_z, send_move_goal, set_suction, run_sorting_sequence ê¸°ì¡´ ë™ì¼) ...
    def get_smart_z(self, depth_m):
        if depth_m <= 0: return -20.0
        target_z = Z_OFFSET_CONSTANT - (depth_m * 1000.0)
        if target_z < -45: target_z = -45
        return target_z

    def send_move_goal(self, x, y, z, r=0.0, mode=1):
        if not self._action_client.wait_for_server(timeout_sec=1.0): return
        goal_msg = PointToPoint.Goal()
        goal_msg.target_pose = [float(x), float(y), float(z), float(r)]
        goal_msg.motion_type = mode 
        self._action_client.send_goal_async(goal_msg)
        time.sleep(2.5) 

    def set_suction(self, enable: bool):
        if self._suction_client.service_is_ready():
            req = SuctionCupControl.Request()
            req.enable_suction = enable
            self._suction_client.call_async(req)
            time.sleep(0.5)

    def run_sorting_sequence(self):
        self.is_robot_busy = True
        targets = []
        for color, data in self.scan_data.items():
            if data['fixed'] is not None:
                targets.append((color, data['fixed'][0], data['fixed'][1], data['depth_m']))
        
        if not targets:
            self.is_robot_busy = False; return

        for color, tx, ty, tz_m in targets:
            final_x = tx + OFFSET_X; final_y = ty + OFFSET_Y
            smart_z = self.get_smart_z(tz_m)
            final_z = smart_z + OFFSET_Z
            self.get_logger().info(f"ğŸ‘‰ Picking {color}: ({final_x:.1f}, {final_y:.1f})")
            
            self.send_move_goal(final_x, final_y, Z_SAFE, mode=1)
            self.set_suction(True)
            self.send_move_goal(final_x, final_y, final_z, mode=1)
            self.send_move_goal(final_x, final_y, Z_SAFE, mode=1)
            dx, dy, dz, dr = DROP_LOCATIONS[color]
            self.send_move_goal(dx, dy, Z_SAFE, mode=1)
            self.send_move_goal(dx, dy, dz, mode=1)
            self.set_suction(False)
            self.send_move_goal(dx, dy, Z_SAFE, mode=1)
            
        self.send_move_goal(150.0, 0.0, 100, mode=1)
        self.is_robot_busy = False

    def mouse_callback(self, event, x, y, flags, param):
        # ë§ˆìš°ìŠ¤ë¡œ ë‹¤ì‹œ ë“œë˜ê·¸í•˜ë©´ Default ROIëŠ” ë¬´ì‹œë˜ê³  ìƒˆë¡œ ê·¸ë ¤ì§
        if event == cv2.EVENT_LBUTTONDOWN:
            self.selecting = True; self.roi_start = (x, y); self.roi_end = (x, y); self.roi_selected = False; self.reset_data()
        elif event == cv2.EVENT_MOUSEMOVE:
            if self.selecting: self.roi_end = (x, y)
        elif event == cv2.EVENT_LBUTTONUP:
            self.selecting = False; self.roi_end = (x, y); self.roi_selected = True
            x1 = min(self.roi_start[0], self.roi_end[0]); y1 = min(self.roi_start[1], self.roi_end[1])
            x2 = max(self.roi_start[0], self.roi_end[0]); y2 = max(self.roi_start[1], self.roi_end[1])
            self.roi_rect = (x1, y1, x2-x1, y2-y1)

    def reset_data(self):
        self.scan_data = {color: {'buffer': [], 'fixed': None, 'depth_m': 0.0} for color in self.color_ranges}
        self.is_collecting = False

    def info_callback(self, msg):
        if self.camera_intrinsics is None:
            self.camera_intrinsics = {'fx': msg.k[0], 'fy': msg.k[4], 'cx': msg.k[2], 'cy': msg.k[5]}
            self.dist_coeffs = np.array(msg.d)

    def depth_callback(self, msg):
        try: self.latest_depth_img = self.bridge.imgmsg_to_cv2(msg, "16UC1")
        except: pass

    def color_callback(self, msg):
        try: frame = self.bridge.imgmsg_to_cv2(msg, "bgr8"); self.process_image(frame)
        except: pass

    def transform_cam_to_robot(self, cam_x, cam_y):
        input_pt = np.array([[[cam_x, cam_y]]], dtype=np.float32)
        robot_pos = cv2.perspectiveTransform(input_pt, TRANSFORM_MATRIX)
        return robot_pos[0][0][0], robot_pos[0][0][1]

    def process_image(self, frame):
        vis_frame = frame.copy()
        if self.selecting and self.roi_start and self.roi_end:
            cv2.rectangle(vis_frame, self.roi_start, self.roi_end, (0, 0, 255), 1)

        if self.roi_selected and self.roi_rect is not None:
            rx, ry, rw, rh = self.roi_rect
            cv2.rectangle(vis_frame, (rx, ry), (rx+rw, ry+rh), (255, 255, 255), 2)
            y_offset = 0
            
            # ì¸¡ì • ì™„ë£Œ ì—¬ë¶€ ì²´í¬ë¥¼ ìœ„í•œ ë³€ìˆ˜
            all_colors_done = False 
            
            for color, data in self.scan_data.items():
                if data['fixed'] is not None:
                    fx, fy = data['fixed']
                    cv2.putText(vis_frame, f"FIXED [{color}]: ({fx:.0f}, {fy:.0f})", (rx, ry - 20 - y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2); y_offset += 20

            frame_roi = frame[ry:ry+rh, rx:rx+rw]
            hsv = cv2.cvtColor(frame_roi, cv2.COLOR_BGR2HSV)
            
            for color_name, ranges in self.color_ranges.items():
                try:
                    mask = np.zeros(hsv.shape[:2], dtype="uint8")
                    for (lower, upper) in ranges:
                        mask = cv2.bitwise_or(mask, cv2.inRange(hsv, np.array(lower), np.array(upper)))
                    mask = cv2.erode(mask, None, iterations=1); mask = cv2.dilate(mask, None, iterations=2)
                    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    
                    for contour in contours:
                        if 500 < cv2.contourArea(contour) < 20000:
                            bx, by, bw, bh = cv2.boundingRect(contour)
                            cx = int(bx + bw/2) + rx; cy = int(by + bh/2) + ry
                            
                            if self.latest_depth_img is not None and self.camera_intrinsics:
                                d_y = min(max(cy, 0), 479); d_x = min(max(cx, 0), 639)
                                depth_mm = self.latest_depth_img[d_y, d_x]
                                
                                if depth_mm > 0:
                                    cam_z = depth_mm / 1000.0
                                    # ì™œê³¡ ë³´ì •
                                    fx = self.camera_intrinsics['fx']; fy = self.camera_intrinsics['fy']
                                    cx_cam = self.camera_intrinsics['cx']; cy_cam = self.camera_intrinsics['cy']
                                    if self.dist_coeffs is not None:
                                        src_pt = np.array([[[float(cx), float(cy)]]], dtype=np.float32)
                                        cam_mat = np.array([[fx, 0, cx_cam], [0, fy, cy_cam], [0, 0, 1]], dtype=np.float32)
                                        dst_pt = cv2.undistortPoints(src_pt, cam_mat, self.dist_coeffs, P=cam_mat)
                                        cx_fixed = dst_pt[0][0][0]; cy_fixed = dst_pt[0][0][1]
                                    else:
                                        cx_fixed, cy_fixed = cx, cy

                                    cam_x = (cx_fixed - cx_cam) * cam_z / fx
                                    cam_y = (cy_fixed - cy_cam) * cam_z / fy
                                    rob_x, rob_y = self.transform_cam_to_robot(cam_x, cam_y)
                                    
                                    if self.scan_data[color_name]['fixed']:
                                        cv2.drawMarker(vis_frame, (cx, cy), (0, 255, 0), cv2.MARKER_CROSS, 20, 2)
                                    else:
                                        cv2.drawMarker(vis_frame, (cx, cy), (0, 0, 255), cv2.MARKER_CROSS, 20, 2)
                                        label = f"{color_name}: {rob_x:.0f},{rob_y:.0f}"
                                        
                                        # [ì¤‘ìš”] ìë™í™” ë¡œì§: ìˆ˜ì§‘ ì¤‘ì´ë©´ ë°ì´í„° ìŒ“ê¸°
                                        if self.is_collecting:
                                            self.scan_data[color_name]['buffer'].append((rob_x, rob_y, cam_z))
                                            cnt = len(self.scan_data[color_name]['buffer'])
                                            label += f" [{cnt}/60]"
                                            
                                            # 60ê°œ ëª¨ì´ë©´ í™•ì •(FIXED)
                                            if cnt >= 60:
                                                avg_x = np.mean([p[0] for p in self.scan_data[color_name]['buffer']])
                                                avg_y = np.mean([p[1] for p in self.scan_data[color_name]['buffer']])
                                                avg_z = np.mean([p[2] for p in self.scan_data[color_name]['buffer']])
                                                self.scan_data[color_name]['fixed'] = (avg_x, avg_y)
                                                self.scan_data[color_name]['depth_m'] = avg_z
                                                print(f"âœ… FIXED {color_name}: Pos=({avg_x:.1f}, {avg_y:.1f})")
                                                # í•˜ë‚˜ë¼ë„ í™•ì •ë˜ë©´ í”Œë˜ê·¸ ì„¤ì •
                                                all_colors_done = True 

                                        cv2.putText(vis_frame, label, (cx-40, cy-20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                except: pass

            # [ì¤‘ìš”] ìë™í™” íŠ¸ë¦¬ê±°: ìˆ˜ì§‘ ì¤‘ì´ì—ˆê³ , ì¸¡ì •ì´ ì™„ë£Œ(Fixed)ë˜ì—ˆìœ¼ë©´ ë°”ë¡œ í”¼í‚¹ ì‹œì‘
            if self.is_collecting and all_colors_done:
                self.is_collecting = False # ìˆ˜ì§‘ ì¤‘ë‹¨
                if not self.is_robot_busy:
                    print("âš¡ Measurement Complete. Auto-triggering Pick Sequence!")
                    threading.Thread(target=self.run_sorting_sequence).start()

        # í™”ë©´ í…ìŠ¤íŠ¸ í‘œì‹œ
        if self.is_robot_busy: cv2.putText(vis_frame, "Robot Working...", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        elif self.is_collecting: cv2.putText(vis_frame, "Auto Measuring...", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)
        else: cv2.putText(vis_frame, "Status: Idle (Waiting for Conveyor)", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        cv2.imshow(self.window_name, vis_frame)
        key = cv2.waitKey(1) & 0xFF
        if key == ord('c'): self.reset_data(); self.is_collecting = True
        elif key == ord('r'): self.reset_data(); self.roi_selected = False; self.roi_rect = None
        elif key == ord('p'): 
            if not self.is_robot_busy: threading.Thread(target=self.run_sorting_sequence).start()
        elif key == 27: rclpy.shutdown()

# ... (main í•¨ìˆ˜ ë™ì¼) ...
def main(args=None):
    rclpy.init(args=args)
    node = ColorSorter()
    try: rclpy.spin(node)
    except KeyboardInterrupt: pass
    finally: node.destroy_node(); rclpy.shutdown(); cv2.destroyAllWindows()

if __name__ == '__main__':
    main()